{'seed': None, 'notes': None, 'non_verbose': 0, 'disable_log': 0, 'validation': 0, 'ignore_other_metrics': 0, 'debug_mode': 0, 'nowand': 1, 'wandb_entity': 'regaz', 'wandb_project': 'mammoth', 'dataset': 'seq-cifar100', 'model': 'der', 'lr': 0.03, 'optim_wd': 0.0, 'optim_mom': 0.0, 'optim_nesterov': 0, 'n_epochs': 50, 'batch_size': 32, 'distributed': 'no', 'buffer_size': 200, 'minibatch_size': 32, 'alpha': 0.3, 'conf_jobnum': 'e59ca26a-ad62-440f-b22b-41b3bc7d7051', 'conf_timestamp': '2023-02-06 11:20:01.839981', 'conf_host': 'engr-mahala04gn', 'accmean_task1': 87.8, 'accmean_task2': 84.05000000000001, 'accmean_task3': 81.43333333333334, 'accmean_task4': 77.825, 'accmean_task5': 75.64, 'accmean_task6': 72.15, 'accmean_task7': 72.17142857142856, 'accmean_task8': 69.01249999999999, 'accmean_task9': 66.78888888888889, 'accmean_task10': 68.55, 'accuracy_1_task1': 87.8, 'accuracy_1_task2': 79.80000000000001, 'accuracy_2_task2': 88.3, 'accuracy_1_task3': 73.7, 'accuracy_2_task3': 80.7, 'accuracy_3_task3': 89.9, 'accuracy_1_task4': 65.9, 'accuracy_2_task4': 75.4, 'accuracy_3_task4': 80.2, 'accuracy_4_task4': 89.8, 'accuracy_1_task5': 60.099999999999994, 'accuracy_2_task5': 70.1, 'accuracy_3_task5': 78.4, 'accuracy_4_task5': 82.6, 'accuracy_5_task5': 87.0, 'accuracy_1_task6': 51.6, 'accuracy_2_task6': 60.099999999999994, 'accuracy_3_task6': 75.5, 'accuracy_4_task6': 77.9, 'accuracy_5_task6': 78.10000000000001, 'accuracy_6_task6': 89.7, 'accuracy_1_task7': 50.4, 'accuracy_2_task7': 60.9, 'accuracy_3_task7': 69.39999999999999, 'accuracy_4_task7': 75.2, 'accuracy_5_task7': 74.7, 'accuracy_6_task7': 83.7, 'accuracy_7_task7': 90.9, 'accuracy_1_task8': 44.0, 'accuracy_2_task8': 55.00000000000001, 'accuracy_3_task8': 64.7, 'accuracy_4_task8': 68.10000000000001, 'accuracy_5_task8': 69.6, 'accuracy_6_task8': 77.3, 'accuracy_7_task8': 85.2, 'accuracy_8_task8': 88.2, 'accuracy_1_task9': 39.900000000000006, 'accuracy_2_task9': 47.5, 'accuracy_3_task9': 58.5, 'accuracy_4_task9': 63.6, 'accuracy_5_task9': 69.0, 'accuracy_6_task9': 71.89999999999999, 'accuracy_7_task9': 80.4, 'accuracy_8_task9': 79.10000000000001, 'accuracy_9_task9': 91.2, 'accuracy_1_task10': 39.4, 'accuracy_2_task10': 50.0, 'accuracy_3_task10': 61.5, 'accuracy_4_task10': 62.6, 'accuracy_5_task10': 67.60000000000001, 'accuracy_6_task10': 72.8, 'accuracy_7_task10': 78.5, 'accuracy_8_task10': 76.9, 'accuracy_9_task10': 82.3, 'accuracy_10_task10': 93.89999999999999, 'forward_transfer': -0.25555555555555576, 'backward_transfer': -23.466666666666665, 'forgetting': 23.466666666666665}
